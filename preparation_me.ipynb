{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Callable\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/raw/triathlon_watch_test_data_final.csv')\n",
    "df_training = pd.read_csv('data/raw/triathlon_watch_training_data_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_baseline_model = df_training.dropna(subset=['User of latest model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_baseline_model = df_training_baseline_model.drop_duplicates(subset='ID')\n",
    "df_training_baseline_model.set_index(\"ID\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Days since Update\n",
      "ID                      \n",
      "C0001              197.0\n",
      "C0003              269.0\n",
      "C0004              172.0\n",
      "C0005              177.0\n",
      "C0006               78.0\n"
     ]
    }
   ],
   "source": [
    "df_training_baseline_model['Most current software update'] = pd.to_datetime(df_training_baseline_model['Most current software update'])\n",
    "\n",
    "# Berechne die Differenz in Tagen zum aktuellen Datum\n",
    "df_training_baseline_model['Days since Update'] = (pd.Timestamp.today() - df_training_baseline_model['Most current software update']).dt.days\n",
    "\n",
    "# Entferne die ursprüngliche Datums-Spalte\n",
    "df_training_baseline_model.drop(columns=['Most current software update'], inplace=True)\n",
    "\n",
    "# Überprüfe die Umwandlung\n",
    "print(df_training_baseline_model[['Days since Update']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age of customer</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ctry</th>\n",
       "      <th>Town</th>\n",
       "      <th>Swimming Hours per Week</th>\n",
       "      <th>Biking Hours per Week</th>\n",
       "      <th>Running Hours per Week</th>\n",
       "      <th>Total Training Hours per Week</th>\n",
       "      <th>VO2 Max</th>\n",
       "      <th>10k Running Time Prediction</th>\n",
       "      <th>Calories Burned per Week</th>\n",
       "      <th>Support Cases of Customer</th>\n",
       "      <th>Customer Years</th>\n",
       "      <th>Goal of Training</th>\n",
       "      <th>Preferred Training Daytime</th>\n",
       "      <th>Subscription Type</th>\n",
       "      <th>Color of Watch</th>\n",
       "      <th>Synchronisation</th>\n",
       "      <th>User of latest model</th>\n",
       "      <th>Days since Update</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C0001</th>\n",
       "      <td>61.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>UK</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.78</td>\n",
       "      <td>4.40</td>\n",
       "      <td>23.08</td>\n",
       "      <td>60.72</td>\n",
       "      <td>2329.95</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Free</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>197.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C0003</th>\n",
       "      <td>57.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>1.55</td>\n",
       "      <td>10.01</td>\n",
       "      <td>4.57</td>\n",
       "      <td>16.13</td>\n",
       "      <td>39.04</td>\n",
       "      <td>54.37</td>\n",
       "      <td>7904.93</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Black</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C0004</th>\n",
       "      <td>30.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>India</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>1.19</td>\n",
       "      <td>12.04</td>\n",
       "      <td>8.64</td>\n",
       "      <td>21.87</td>\n",
       "      <td>71.59</td>\n",
       "      <td>33.92</td>\n",
       "      <td>10839.81</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Competition</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Free</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C0005</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Munich</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.92</td>\n",
       "      <td>7.84</td>\n",
       "      <td>49.09</td>\n",
       "      <td>44.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Recreation</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Black</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C0006</th>\n",
       "      <td>63.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>India</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>0.80</td>\n",
       "      <td>5.88</td>\n",
       "      <td>0.67</td>\n",
       "      <td>7.35</td>\n",
       "      <td>13.91</td>\n",
       "      <td>62.46</td>\n",
       "      <td>3575.96</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Recreation</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Black</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C0996</th>\n",
       "      <td>28.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.79</td>\n",
       "      <td>5.46</td>\n",
       "      <td>61.05</td>\n",
       "      <td>40.38</td>\n",
       "      <td>2589.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Recreation</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Black</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C0997</th>\n",
       "      <td>54.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>1.80</td>\n",
       "      <td>4.45</td>\n",
       "      <td>1.35</td>\n",
       "      <td>7.61</td>\n",
       "      <td>34.50</td>\n",
       "      <td>56.38</td>\n",
       "      <td>4104.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Recreation</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Free</td>\n",
       "      <td>Black</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C0998</th>\n",
       "      <td>35.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>USA</td>\n",
       "      <td>New York</td>\n",
       "      <td>3.91</td>\n",
       "      <td>0.57</td>\n",
       "      <td>5.57</td>\n",
       "      <td>10.05</td>\n",
       "      <td>58.63</td>\n",
       "      <td>37.27</td>\n",
       "      <td>5078.45</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Black</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C0999</th>\n",
       "      <td>31.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Germayn</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>0.36</td>\n",
       "      <td>4.63</td>\n",
       "      <td>5.16</td>\n",
       "      <td>10.15</td>\n",
       "      <td>66.46</td>\n",
       "      <td>37.98</td>\n",
       "      <td>5184.27</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Free</td>\n",
       "      <td>Black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000</th>\n",
       "      <td>27.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>India</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>0.43</td>\n",
       "      <td>7.46</td>\n",
       "      <td>5.55</td>\n",
       "      <td>13.44</td>\n",
       "      <td>61.81</td>\n",
       "      <td>36.07</td>\n",
       "      <td>6827.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Black</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>971 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age of customer     Sex       Ctry        Town  \\\n",
       "ID                                                      \n",
       "C0001             61.0   Other         UK  Birmingham   \n",
       "C0003             57.0   Other  Australia      Sydney   \n",
       "C0004             30.0   Other      India   Bangalore   \n",
       "C0005             21.0    Male    Germany      Munich   \n",
       "C0006             63.0    Male      India      Mumbai   \n",
       "...                ...     ...        ...         ...   \n",
       "C0996             28.0  Female  Australia    Brisbane   \n",
       "C0997             54.0  Female  Australia   Melbourne   \n",
       "C0998             35.0   Other        USA    New York   \n",
       "C0999             31.0   Other    Germayn      Berlin   \n",
       "C1000             27.0    Male      India      Mumbai   \n",
       "\n",
       "       Swimming Hours per Week  Biking Hours per Week  Running Hours per Week  \\\n",
       "ID                                                                              \n",
       "C0001                     2.52                   0.10                    1.78   \n",
       "C0003                     1.55                  10.01                    4.57   \n",
       "C0004                     1.19                  12.04                    8.64   \n",
       "C0005                     2.25                   4.67                    0.92   \n",
       "C0006                     0.80                   5.88                    0.67   \n",
       "...                        ...                    ...                     ...   \n",
       "C0996                     2.38                   0.28                    2.79   \n",
       "C0997                     1.80                   4.45                    1.35   \n",
       "C0998                     3.91                   0.57                    5.57   \n",
       "C0999                     0.36                   4.63                    5.16   \n",
       "C1000                     0.43                   7.46                    5.55   \n",
       "\n",
       "       Total Training Hours per Week  VO2 Max  10k Running Time Prediction  \\\n",
       "ID                                                                           \n",
       "C0001                           4.40    23.08                        60.72   \n",
       "C0003                          16.13    39.04                        54.37   \n",
       "C0004                          21.87    71.59                        33.92   \n",
       "C0005                           7.84    49.09                        44.97   \n",
       "C0006                           7.35    13.91                        62.46   \n",
       "...                              ...      ...                          ...   \n",
       "C0996                           5.46    61.05                        40.38   \n",
       "C0997                           7.61    34.50                        56.38   \n",
       "C0998                          10.05    58.63                        37.27   \n",
       "C0999                          10.15    66.46                        37.98   \n",
       "C1000                          13.44    61.81                        36.07   \n",
       "\n",
       "       Calories Burned per Week  Support Cases of Customer  Customer Years  \\\n",
       "ID                                                                           \n",
       "C0001                   2329.95                        2.0             1.0   \n",
       "C0003                   7904.93                        2.0             1.0   \n",
       "C0004                  10839.81                        2.0             0.0   \n",
       "C0005                       NaN                        3.0             0.0   \n",
       "C0006                   3575.96                        3.0             3.0   \n",
       "...                         ...                        ...             ...   \n",
       "C0996                   2589.77                        0.0             3.0   \n",
       "C0997                   4104.15                        0.0             3.0   \n",
       "C0998                   5078.45                        4.0             6.0   \n",
       "C0999                   5184.27                        3.0             3.0   \n",
       "C1000                   6827.69                        0.0             7.0   \n",
       "\n",
       "      Goal of Training Preferred Training Daytime Subscription Type  \\\n",
       "ID                                                                    \n",
       "C0001          Fitness                    Evening              Free   \n",
       "C0003          Fitness                    Evening           Premium   \n",
       "C0004      Competition                  Afternoon              Free   \n",
       "C0005       Recreation                    Evening           Premium   \n",
       "C0006       Recreation                    Morning             Basic   \n",
       "...                ...                        ...               ...   \n",
       "C0996       Recreation                    Morning           Premium   \n",
       "C0997       Recreation                  Afternoon              Free   \n",
       "C0998          Fitness                  Afternoon           Premium   \n",
       "C0999          Fitness                    Evening              Free   \n",
       "C1000          Fitness                  Afternoon           Premium   \n",
       "\n",
       "      Color of Watch Synchronisation  User of latest model  Days since Update  \n",
       "ID                                                                             \n",
       "C0001          White             Yes                   1.0              197.0  \n",
       "C0003          Black             Yes                   0.0              269.0  \n",
       "C0004          White             Yes                   1.0              172.0  \n",
       "C0005          Black              No                   1.0              177.0  \n",
       "C0006          Black             Yes                   0.0               78.0  \n",
       "...              ...             ...                   ...                ...  \n",
       "C0996          Black             Yes                   0.0              392.0  \n",
       "C0997          Black             Yes                   0.0               87.0  \n",
       "C0998          Black             Yes                   1.0              161.0  \n",
       "C0999          Black             NaN                   1.0              230.0  \n",
       "C1000          Black             Yes                   0.0              245.0  \n",
       "\n",
       "[971 rows x 20 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training_baseline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7538461538461538\n",
      "Confusion Matrix:\n",
      " [[93 17]\n",
      " [31 54]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.85      0.79       110\n",
      "         1.0       0.76      0.64      0.69        85\n",
      "\n",
      "    accuracy                           0.75       195\n",
      "   macro avg       0.76      0.74      0.74       195\n",
      "weighted avg       0.75      0.75      0.75       195\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/intro_ds_ai/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ersetze \"Germayn\" durch \"Germany\" in der Spalte `Ctry`\n",
    "df_training_baseline_model['Ctry'] = df_training_baseline_model['Ctry'].replace('Germayn', 'Germany')\n",
    "\n",
    "# Ersetze \"UnknownLand\" durch np.nan (fehlender Wert)\n",
    "df_training_baseline_model['Ctry'] = df_training_baseline_model['Ctry'].replace('UnknownLand', np.nan)\n",
    "\n",
    "# Ersetze -1 in \"Age of customer\" durch np.nan\n",
    "df_training_baseline_model['Age of customer'] = df_training_baseline_model['Age of customer'].replace(-1, np.nan)\n",
    "\n",
    "df_training_baseline_model['Most current software update'] = pd.to_datetime(df_training_baseline_model['Most current software update'])\n",
    "df_training_baseline_model['date_numeric'] = (df_training_baseline_model['Most current software update'] - pd.Timestamp(\"2000-01-01\")).dt.days\n",
    "df_training_baseline_model.drop(columns=['Most current software update'], inplace=True)  # Original-Datumsspalte entfernen\n",
    "\n",
    "\n",
    "# One-Hot-Encoding für kategoriale Variablen\n",
    "df_training_baseline_model = pd.get_dummies(\n",
    "    df_training_baseline_model, \n",
    "    columns=['Sex', 'Ctry', 'Town', 'Subscription Type', \"Goal of Training\", \"Preferred Training Daytime\", \"Color of Watch\", 'Synchronisation'], \n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Definiere die Features (X) und die Zielvariable (y)\n",
    "X = df_training_baseline_model.drop('User of latest model', axis=1)\n",
    "y = df_training_baseline_model['User of latest model']\n",
    "\n",
    "# Teile die Daten in Trainings- und Testdaten auf\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialisiere das Modell\n",
    "model = LogisticRegression()\n",
    "\n",
    "\n",
    "# Trainiere das Modell\n",
    "model.fit(X_train.fillna(0), y_train)\n",
    "\n",
    "# Mache Vorhersagen auf den Testdaten\n",
    "y_pred = model.predict(X_test.fillna(0))\n",
    "\n",
    "# Evaluierung des Modells\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'NAType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Trainiere das Modell\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Mache Vorhersagen auf den Testdaten\u001b[39;00m\n\u001b[1;32m     29\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/intro_ds_ai/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/intro_ds_ai/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1222\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1220\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1222\u001b[0m X, y \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[1;32m   1223\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1224\u001b[0m     X,\n\u001b[1;32m   1225\u001b[0m     y,\n\u001b[1;32m   1226\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1227\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m_dtype,\n\u001b[1;32m   1228\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1229\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1230\u001b[0m )\n\u001b[1;32m   1231\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/intro_ds_ai/lib/python3.12/site-packages/sklearn/utils/validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/intro_ds_ai/lib/python3.12/site-packages/sklearn/utils/validation.py:1370\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1366\u001b[0m     )\n\u001b[1;32m   1368\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[0;32m-> 1370\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1371\u001b[0m     X,\n\u001b[1;32m   1372\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   1373\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[1;32m   1374\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1375\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[1;32m   1376\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   1377\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39mforce_writeable,\n\u001b[1;32m   1378\u001b[0m     ensure_all_finite\u001b[38;5;241m=\u001b[39mensure_all_finite,\n\u001b[1;32m   1379\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m   1380\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[1;32m   1381\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[1;32m   1382\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[1;32m   1383\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m   1384\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1385\u001b[0m )\n\u001b[1;32m   1387\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1389\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/intro_ds_ai/lib/python3.12/site-packages/sklearn/utils/validation.py:973\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pandas_requires_conversion:\n\u001b[1;32m    969\u001b[0m     \u001b[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;66;03m# nans\u001b[39;00m\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[1;32m    972\u001b[0m     new_dtype \u001b[38;5;241m=\u001b[39m dtype_orig \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[0;32m--> 973\u001b[0m     array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(new_dtype)\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[1;32m    975\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/intro_ds_ai/lib/python3.12/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/intro_ds_ai/lib/python3.12/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    432\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    433\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    434\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    435\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[1;32m    436\u001b[0m )\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/intro_ds_ai/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/intro_ds_ai/lib/python3.12/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/intro_ds_ai/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/intro_ds_ai/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/intro_ds_ai/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'NAType'"
     ]
    }
   ],
   "source": [
    "# Ersetze \"Germayn\" durch \"Germany\" in der Spalte `Ctry`\n",
    "df_training_baseline_model['Ctry'] = df_training_baseline_model['Ctry'].replace('Germayn', 'Germany')\n",
    "# Ersetze \"UnknownLand\" durch NaN (fehlender Wert)\n",
    "df_training_baseline_model['Ctry'] = df_training_baseline_model['Ctry'].replace('UnknownLand', pd.NA)\n",
    "# Ersetze -1 in \"Age of customer\" durch NaN\n",
    "df_training_baseline_model['Age of customer'] = df_training_baseline_model['Age of customer'].replace(-1, pd.NA)\n",
    "\n",
    "df_training_baseline_model = pd.get_dummies(df_training_baseline_model, columns=['Ctry', 'Sex', 'Town', 'Preferred Training Daytime', 'Subscription Type', 'Color of Watch', 'Synchronisation'], drop_first=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Definiere die Features (X) und die Zielvariable (y)\n",
    "X = df_training_baseline_model.drop('User of latest model', axis=1)\n",
    "y = df_training_baseline_model['User of latest model']\n",
    "\n",
    "# Teile die Daten in Trainings- und Testdaten auf\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Initialisiere das Modell\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Trainiere das Modell\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Mache Vorhersagen auf den Testdaten\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluierung des Modells\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "X = df_training_baseline_model.drop('User of latest model', axis=1)\n",
    "y = df_training_baseline_model['User of latest model']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Spalten für numerische und kategorische Features\n",
    "numeric_features = ['Age of customer', 'Swimming Hours per Week', 'Biking Hours per Week', 'Running Hours per Week', 'Total Training Hours per Week', 'VO2 Max', 'Calories Burned per Week', 'Support Cases of Customer', 'Customer Years']\n",
    "categorical_features = ['Sex', 'Ctry', 'Town', 'Preferred Training Daytime', 'Subscription Type', 'Color of Watch', 'Synchronisation']\n",
    "\n",
    "# Transformationen für numerische und kategorische Features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Fehlende Werte durch Median ersetzen\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),  # Fehlende Werte durch 'missing' ersetzen\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-Hot-Encoding\n",
    "])\n",
    "\n",
    "# Kombination der Transformationen in einem ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Funktionen für Transformationen in die Pipeline einbinden\n",
    "custom_transformer = FunctionTransformer(custom_transform_baseline)\n",
    "\n",
    "# Gesamte Pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('custom_transform', custom_transformer),  # unktionen für Transformationen\n",
    "    ('preprocessor', preprocessor),  # Vorverarbeitung (Imputation, Encoding)\n",
    "    ('classifier', LogisticRegression(max_iter=1000))  # Logistische Regression\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_synchronisation(df):\n",
    "    \"\"\"\n",
    "    Füllt fehlende Werte in 'Synchronisation' mit Regression Imputation (Logistische Regression).\n",
    "    \n",
    "    Verwendet:\n",
    "    - 'VO2 Max' als Prädiktor für 'Synchronisation'\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame mit fehlenden Werten in 'Synchronisation'.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame mit imputierten Werten für 'Synchronisation'.\n",
    "    \"\"\"\n",
    "    df = df.copy()  # Verhindert inplace-Änderungen\n",
    "    \n",
    "    # Überprüfen, ob 'Synchronisation' eine kategoriale Variable ist\n",
    "    if df['Synchronisation'].dtype != 'object':\n",
    "        df['Synchronisation'] = df['Synchronisation'].astype(str)\n",
    "\n",
    "    # Label-Encoding für 'Synchronisation' (kategoriale Variable)\n",
    "    le = LabelEncoder()\n",
    "    df['Synchronisation Encoded'] = le.fit_transform(df['Synchronisation'])\n",
    "\n",
    "    # Aufteilung: Trainingsdaten (ohne NaN) und fehlende Werte\n",
    "    train_data = df.dropna(subset=['Synchronisation Encoded'])  # Nur Zeilen ohne NaN\n",
    "    missing_data = df[df['Synchronisation Encoded'].isna()]  # Zeilen mit NaN\n",
    "\n",
    "    if missing_data.empty:\n",
    "        return df  # Falls keine fehlenden Werte, nichts tun\n",
    "\n",
    "    # Logistische Regression für kategoriale Zielvariable\n",
    "    imputer = IterativeImputer(estimator=LogisticRegression(max_iter=1000, random_state=42), max_iter=10, random_state=42)\n",
    "\n",
    "    # Nur relevante Spalten für Imputation\n",
    "    imputed_values = imputer.fit_transform(train_data[['Synchronisation Encoded', 'VO2 Max']])\n",
    "\n",
    "    # Setze die imputierten Werte zurück in das ursprüngliche DataFrame\n",
    "    df.loc[missing_data.index, 'Synchronisation Encoded'] = imputed_values[:, 0].round().astype(int)\n",
    "\n",
    "    # Rückumwandlung in ursprüngliche Kategorien\n",
    "    df['Synchronisation'] = le.inverse_transform(df['Synchronisation Encoded'].astype(int))\n",
    "\n",
    "    # Entferne die temporäre numerische Spalte\n",
    "    df = df.drop(columns=['Synchronisation Encoded'])\n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro_ds_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
