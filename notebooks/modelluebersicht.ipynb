{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1️⃣ Lineare Modelle  \n",
    "| Modell                           | Python Package (Import)                                             | Beschreibung                                                                      | Hyperparameter                          | Warnhinweise                                                                          |\n",
    "|----------------------------------|--------------------------------------------------------------------|----------------------------------------------------------------------------------|-----------------------------------------|--------------------------------------------------------------------------------------|\n",
    "| Logistische Regression           | from sklearn.linear_model import LogisticRegression                | Klassischer linearer Klassifikator mit Sigmoid-Funktion.                         | C, solver, penalty                      | Braucht ≥ 100 Samples pro Klasse. Funktioniert nicht gut bei hochgradig korrelierten Features. |\n",
    "| Ridge Classifier                 | from sklearn.linear_model import RidgeClassifier                   | Logistische Regression mit L2-Regularisierung.                                   | alpha, solver                           | Besser als logistische Regression für hochdimensionale Daten (≥ 1.000 Features). |\n",
    "| Lasso Classifier                 | from sklearn.linear_model import Lasso                             | Logistische Regression mit L1-Regularisierung (führt zu sparsamen Modellen).    | alpha                                    | Kann instabil sein bei < 500 Samples.                                                |\n",
    "| Elastic Net Classifier           | from sklearn.linear_model import ElasticNet                        | Kombination aus Ridge- und Lasso-Regularisierung.                               | alpha, l1_ratio                         | Gut bei > 1.000 Features, wenn viele irrelevante Variablen vorhanden sind.          |\n",
    "| Lineare Diskriminanzanalyse (LDA) | from sklearn.discriminant_analysis import LinearDiscriminantAnalysis | Nutzt multivariate Normalverteilungen zur Trennung der Klassen.                  | solver, shrinkage                       | Funktioniert schlecht, wenn Features stark korreliert sind. Mindestens 500+ Samples empfohlen. |\n",
    "| Quadratische Diskriminanzanalyse (QDA) | from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis | Erweitert LDA mit nichtlinearen Entscheidungsgrenzen.                          | reg_param                               | Anfällig für Overfitting bei < 1.000 Samples.                                        |\n",
    "| Perceptron                       | from sklearn.linear_model import Perceptron                        | Einfachstes neuronales Netz, trainiert mit SGD.                                  | penalty, alpha, max_iter                | Nicht für nicht-linear trennbare Daten geeignet.                                    |\n",
    "| SGD Classifier                   | from sklearn.linear_model import SGDClassifier                     | Stochastischer Gradientenabstieg für große Datenmengen.                          | loss, penalty, alpha                    | Empfohlen für > 10.000 Samples.                                                     |\n",
    "| Passive Aggressive Classifier    | from sklearn.linear_model import PassiveAggressiveClassifier       | Online-Learning-Modell für inkrementelles Training.                              | C, max_iter                             | Braucht ≥ 10.000 Datenpunkte für stabiles Training.                                 |\n",
    "\n",
    "2️⃣ Support Vector Machines (SVMs)  \n",
    "| Modell                           | Python Package (Import)                                             | Beschreibung                                                                      | Hyperparameter                          | Warnhinweise                                                                          |\n",
    "|----------------------------------|--------------------------------------------------------------------|----------------------------------------------------------------------------------|-----------------------------------------|--------------------------------------------------------------------------------------|\n",
    "| SVC (Support Vector Classifier)  | from sklearn.svm import SVC                                        | Klassischer SVM für binäre Klassifikation.                                       | C, kernel, gamma                        | Langsam für > 10.000 Samples.                                                       |\n",
    "| LinearSVC                        | from sklearn.svm import LinearSVC                                   | Lineare Version von SVC für große Datenmengen.                                   | C, penalty, loss                        | Besser als SVC für > 50.000 Samples.                                                |\n",
    "| NuSVC                            | from sklearn.svm import NuSVC                                      | Alternative SVM mit Nu-Parameter.                                                 | nu, kernel, gamma                       | Komplexer zu optimieren als SVC.                                                    |\n",
    "\n",
    "3️⃣ Naive Bayes Modelle  \n",
    "| Modell                           | Python Package (Import)                                             | Beschreibung                                                                      | Hyperparameter                          | Warnhinweise                                                                          |\n",
    "|----------------------------------|--------------------------------------------------------------------|----------------------------------------------------------------------------------|-----------------------------------------|--------------------------------------------------------------------------------------|\n",
    "| GaussianNB                       | from sklearn.naive_bayes import GaussianNB                          | Annahme: Normalverteilte Features.                                                | Keine                                   | Braucht ≥ 100 Samples pro Klasse.                                                   |\n",
    "| MultinomialNB                    | from sklearn.naive_bayes import MultinomialNB                       | Für diskrete Merkmale wie Wortfrequenzen.                                        | alpha                                   | Nicht für kontinuierliche Daten geeignet.                                           |\n",
    "| BernoulliNB                      | from sklearn.naive_bayes import BernoulliNB                         | Für binäre Features (z. B. Dokumentklassifikation).                              | alpha                                   | Erwartet binäre oder 0/1-diskretisierte Features.                                   |\n",
    "| ComplementNB                      | from sklearn.naive_bayes import ComplementNB                       | Optimiert für unbalancierte Klassen.                                             | alpha                                   | Besser als MultinomialNB für sehr unbalancierte Daten.                             |\n",
    "\n",
    "4️⃣ Neuronale Netze & Deep Learning  \n",
    "| Modell                           | Python Package (Import)                                             | Beschreibung                                                                      | Hyperparameter                          | Warnhinweise                                                                          |\n",
    "|----------------------------------|--------------------------------------------------------------------|----------------------------------------------------------------------------------|-----------------------------------------|--------------------------------------------------------------------------------------|\n",
    "| MLPClassifier                     | from sklearn.neural_network import MLPClassifier                    | Einfaches neuronales Netz mit Backpropagation.                                   | hidden_layer_sizes, activation          | Benötigt ≥ 5.000 Datenpunkte für zuverlässige Ergebnisse.                           |\n",
    "| Keras Sequential Model            | from tensorflow.keras.models import Sequential                      | Mehrschichtiges neuronales Netz.                                                 | epochs, batch_size, optimizer           | Benötigt GPU für schnelles Training.                                                |\n",
    "| FastAI Tabular Model              | from fastai.tabular.all import tabular_learner                     | Speziell für strukturierte Daten optimiertes Netz.                               | layers, emb_drop, ps                    | Sehr gut für kleine bis mittelgroße Tabellendaten (ab 10.000 Samples).               |\n",
    "| Transformer-Based Classifier      | from transformers import AutoModelForSequenceClassification        | Neuronales Netz auf Basis von BERT/GPT.                                          | learning_rate, num_labels, hidden_size  | Braucht große Datenmengen (50.000+ Samples) und viel Rechenleistung.               |\n",
    "| Capsule Networks                  | from keras.layers import Capsule                                    | Alternative zu CNNs mit besserer Generalisierung.                                 | num_capsule, dim_capsule                | Rechenintensiv, ab 100.000+ Samples empfohlen.                                      |\n",
    "\n",
    "5️⃣ Dichtebasierte Modelle  \n",
    "| Modell                           | Python Package (Import)                                             | Beschreibung                                                                      | Hyperparameter                          | Warnhinweise                                                                          |\n",
    "|----------------------------------|--------------------------------------------------------------------|----------------------------------------------------------------------------------|-----------------------------------------|--------------------------------------------------------------------------------------|\n",
    "| K-Nearest Neighbors (KNN)        | from sklearn.neighbors import KNeighborsClassifier                | Klassifikator, der die Klasse basierend auf den K nächsten Nachbarn vorhersagt.   | n_neighbors, weights, metric            | Empfohlen für kleinere Datensätze (bis ca. 10.000 Samples). Sehr langsam bei großen Datenmengen. |\n",
    "| DBSCAN (Density-Based Spatial Clustering of Applications with Noise) | from sklearn.cluster import DBSCAN  | Dichtebasiertes Clustering, das auch Rauschen und Ausreißer identifizieren kann.  | eps, min_samples, metric                | Nicht gut bei hochdimensionalen Daten (> 10.000 Features). Schwierig bei sehr ungleichmäßigen Dichteverteilungen. |\n",
    "| Nearest Centroid Classifier      | from sklearn.neighbors import NearestCentroid                    | Klassifikator, der die Klasse anhand des nächsten Zentrums eines Clusters vorhersagt. | Keine                                   | Gut für strukturierte, gut trennbare Daten. Kann bei großen Datensätzen langsamer sein. |\n",
    "| Locally Weighted Learning        | from sklearn.neighbors import KNeighborsClassifier                | Speziell für lokale Regression und Klassifikation, bei der jedes Sample unterschiedliche Gewichtungen hat. | n_neighbors, weights                   | Benötigt kleinere Datensätze (bis ca. 5.000). Empfindlich gegenüber Rauschen. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
